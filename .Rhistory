#merge the calendar
left_join(calendar %>% d2int(), by = "d") %>%
#merge the prices
left_join(prices, by = c("store_id", "item_id", "wm_yr_wk")) %>%
#clear memory
free()
#merge the two other files
train <- train %>%
#merge the calendar
left_join(calendar %>% d2int(), by = "d") %>%
#merge the prices
left_join(prices, by = c("store_id", "item_id", "wm_yr_wk"))
#decrease memory usage
free()
#take a closer look at the data
View(train)
#
train <- train %>%
select(-wm_yr_wk) %>%
mutate(demand = as.numeric(demand)) %>%
mutate_if(is.factor, as.integer) %>%
#introduce the additional features
train <- train %>%
demand_features() %>%
filter(d >= FIRST_PREDICTION_DAY | !is.na(roll_lag28_w28))
#decrease memory usage
free()
#
train <- train %>%
select(-wm_yr_wk) %>%
mutate(demand = as.numeric(demand)) %>%
mutate_if(is.factor, as.integer)
#take a closer look at the data
View(train)
#decrease memory usage
free()
#decrease memory usage
free()
#introduce the additional features
train <- train %>%
demand_features() %>%
filter(d >= FIRST_PREDICTION_DAY | !is.na(roll_lag28_w28))
#decrease memory usage
free()
#decrease memory usage
free()
setwd("~/St. Gallen/2. Semester/Big Data & Data Science/M5 Forecasting Challenge")
#importing relevant libraries
library(tidyverse)
library(data.table)
library(RcppRoll)
devtools::install_github('catboost/catboost', subdir = 'catboost/R-package')
library(catboost)
library(lightgbm)
#garbage collector for training as a lot of memory is used
free <- function() invisible(gc())
# Create Constants for prediction
# First day to start prediction
FIRST_PREDICTION_DAY <- 1914
# Predictions need to be made for 28 days
LENGTH_PREDICTION <- 28
#Import the data
#special events like the superbowl are dropped
calendar <- fread("calendar.csv", stringsAsFactors = TRUE,
drop = c("date", "weekday", "event_type_1", "event_type_2"))
#drop first 1000 for conserving memory
train <- fread("sales_train_validation.csv", stringsAsFactors = TRUE, drop = paste0("d_", 1:1000))
prices <- fread("sell_prices.csv", stringsAsFactors = TRUE)
#get an overview of the data
#show dimensions
dim(calendar)
dim(train)
dim(prices)
#take a closer look at the data
View(train)
View(prices)
View(calendar)
#create additional features
# Functions
#what does it do?
d2int <- function(X) {
X %>% extract(d, into = "d", "([0-9]+)", convert = TRUE)
}
#Create additional features for the demand
demand_features <- function(X) {
X %>%
group_by(id) %>%
mutate(lag_7 = dplyr::lag(demand, 7),
lag_28 = dplyr::lag(demand, 28),
roll_lag7_w7 = roll_meanr(lag_7, 7),
roll_lag7_w28 = roll_meanr(lag_7, 28),
roll_lag28_w7 = roll_meanr(lag_28, 7),
roll_lag28_w28 = roll_meanr(lag_28, 28)) %>%
ungroup()
}
#decrease memory by removing unused parts
free()
# Fill in blank values for prediction after the last day of data
train[, paste0("d_", FIRST_PREDICTION_DAY:(FIRST_PREDICTION_DAY + 2 * LENGTH_PREDICTION - 1))] <- NA
free()
#clean and transpose the data
train <- train %>%
#eliminate validation to save memory
mutate(id = gsub("_validation", "", id)) %>%
#transpose the data to create a better overview
gather("d", "demand", -id, -item_id, -dept_id, -cat_id, -store_id, -state_id) %>%
#convert the day value (e.g. d_1) to an integer for every row of the
d2int()
#decrease memory usage
free()
#merge the two other files
train <- train %>%
#merge the calendar
left_join(calendar %>% d2int(), by = "d") %>%
#merge the prices
left_join(prices, by = c("store_id", "item_id", "wm_yr_wk"))
#importing relevant libraries
library(tidyverse)
library(data.table)
library(RcppRoll)
library(dplyr)
train <- fread("sales_train_validation.csv", stringsAsFactors = TRUE)
free <- function() invisible(gc())
train <- train %>%
#eliminate valitrainion to save memory
mutate(id = gsub("_valitrainion", "", id)) %>%
select(-item_id) %>%
select(-dept_id) %>%
select(-cat_id) %>%
select(-store_id) %>%
select(-state_id)
free()
#transpose the data
train = t(train)
free()
#write first row as column header
names(train) <- as.matrix(train[1, ])
train <- train[-1, ]
free()
View(train)
#write first row as column header
names(train) <- as.matrix(train[2, ])
train <- train[-1, ]
View(train)
#importing relevant libraries
library(tidyverse)
library(data.table)
library(RcppRoll)
library(dplyr)
train <- fread("sales_train_validation.csv", stringsAsFactors = TRUE)
free <- function() invisible(gc())
train <- train %>%
#eliminate valitrainion to save memory
mutate(id = gsub("_valitrainion", "", id)) %>%
select(-item_id) %>%
select(-dept_id) %>%
select(-cat_id) %>%
select(-store_id) %>%
select(-state_id)
free()
#transpose the data
train = t(train)
View(train)
setwd("~/St. Gallen/2. Semester/Big Data & Data Science/M5 Forecasting Challenge")
#importing relevant libraries
library(tidyverse)
library(data.table)
library(RcppRoll)
library(dplyr)
train <- fread("sales_train_validation.csv", stringsAsFactors = TRUE)
free <- function() invisible(gc())
train <- train %>%
#eliminate valitrainion to save memory
mutate(id = gsub("_valitrainion", "", id)) %>%
select(-item_id) %>%
select(-dept_id) %>%
select(-cat_id) %>%
select(-store_id) %>%
select(-state_id)
free()
#transpose the data
train = t(train)
free()
#write first row as column header
library(tidyverse)
train %>%
# rename with first row
set_names(train[1, ]) %>%
# delete the first row
slice(-1)
train %>%
set_names(train[1, ])
str(train)
train <- set_names(train,nm = train[1, ])
#importing relevant libraries
library(tidyverse)
library(data.table)
library(RcppRoll)
library(dplyr)
train <- fread("sales_train_validation.csv", stringsAsFactors = FALSE)
free <- function() invisible(gc())
train <- train %>%
#eliminate valitrainion to save memory
mutate(id = gsub("_valitrainion", "", id)) %>%
select(-item_id) %>%
select(-dept_id) %>%
select(-cat_id) %>%
select(-store_id) %>%
select(-state_id)
free()
#transpose the data
train = t(train)
free()
#write first row as column header
library(tidyverse)
train <- set_names(train,nm = train[1, ])
free()
train[1,] <- lapply(train[1,], as.character)
View(train)
#importing relevant libraries
library(tidyverse)
library(data.table)
setwd("~/St. Gallen/2. Semester/Big Data & Data Science/M5 Forecasting Challenge")
#importing relevant libraries
library(tidyverse)
library(data.table)
library(RcppRoll)
library(dplyr)
library(janitor)
library(forecast)
train <- fread("sales_train_validation.csv", stringsAsFactors = FALSE)
calendar <- fread("calendar.csv", stringsAsFactors = TRUE)
free <- function() invisible(gc())
train <- train %>%
#eliminate valitrainion to save memory
mutate(id = gsub("_validation", "", id)) %>%
select(-item_id) %>%
select(-dept_id) %>%
select(-cat_id) %>%
select(-store_id) %>%
select(-state_id) %>%
mutate_if(is.factor, as.integer)
#clear the memory
free()
#transpose the data
train = t(train)
#write first row as column header
train <- train %>%
row_to_names(row_number = 1)
#create test dataframe
new_train = train[,9]
new_train <- as.integer(new_train)
new_train <- as.data.frame(new_train)
#add features
new_train$date = calendar$date[1:1913]
new_train$day = calendar$weekday[1:1913]
new_train$week = week(new_train$date)
#eliminate first 6 entries and last 4 entries to have full weeks only
new_train = new_train[-c(1:6, 1910:1913),]
#rename column
names(new_train)[names(new_train) == "quantity"] <- "new_train"
View(new_train)
#rename column
names(my_data)[1] <- "quantity"
#rename column
names(new_train)[1] <- "quantity"
View(new_train)
#create time series data
product_ts = ts(new_train$quantity, frequency = 7)
plot(product_ts)
### Create Test and Training Data
######################################################
index = tail(1:nrow(new_train),28)
train_product = new_train[-index,]
test_product = new_train[index,]
for (w in unique(test_product$week)){
print(w)
}
train_product_ts = ts(train_product$new_train, frequency = 7)
train_product_ts = ts(train_product$quantity, frequency = 7)
forecast = naive(train_product_ts, h = 7)
tail(train_product$new_train,1)
autoplot(forecast, PI = FALSE)
# RMSE calculation
RMSE=function(actual, predicted){
rmse = sqrt(mean((actual-predicted)^2))
return(rmse)
}
walkforward_evaluation = function(train_product, test_product){
history = train_product
performance_collector = c()
for (w in unique(test_product$week_of_year)){
#create time series of history
history_ts = ts(history$quantity, frequency = 7)
#make forecast and assess RMSE
predicted = naive(history_ts, h = 7)$mean
actual = test_product[week_of_year == w,,]$quantity
performance = RMSE(actual, predicted)
# update history and collect performance
history = rbind(history, test_product[week_of_year == w,,])
performance_collector = c(performance_collector, performance)
}
return(performance_collector)
}
naive_error = walkforward_evaluation(train_product, test_product)
mean(naive_error)
naive_error
walkforward_evaluation = function(train_product, test_product){
history = train_product
performance_collector = c()
for (w in unique(test_product$week)){
#create time series of history
history_ts = ts(history$quantity, frequency = 7)
#make forecast and assess RMSE
predicted = naive(history_ts, h = 7)$mean
actual = test_product[week == w,,]$quantity
performance = RMSE(actual, predicted)
# update history and collect performance
history = rbind(history, test_product[week == w,,])
performance_collector = c(performance_collector, performance)
}
return(performance_collector)
}
naive_error = walkforward_evaluation(train_product, test_product)
walkforward_evaluation = function(train_product, test_product){
history = train_product
performance_collector = c()
for (w in unique(test_product$week)){
#create time series of history
history_ts = ts(history$quantity, frequency = 7)
#make forecast and assess RMSE
predicted = naive(history_ts, h = 7)$mean
actual = test_product[week = w,,]$quantity
performance = RMSE(actual, predicted)
# update history and collect performance
history = rbind(history, test_product[week = w,,])
performance_collector = c(performance_collector, performance)
}
return(performance_collector)
}
naive_error = walkforward_evaluation(train_product, test_product)
for (w in unique(test_product$week)){
#create time series of history
history_ts = ts(history$quantity, frequency = 7)
#make forecast and assess RMSE
predicted = naive(history_ts, h = 7)$mean
actual = test_product[week == w,,]$quantity
performance = RMSE(actual, predicted)
# update history and collect performance
history = rbind(history, test_product[week == w,,])
performance_collector = c(performance_collector, performance)
}
for (w in unique(test_product$week)){
actual = test_product[week == w,,]$quantity
print(actual)
}
View(test_product)
actual = test_product[13,,]$quantity
actual
setwd("~/St. Gallen/2. Semester/Big Data & Data Science/8. Modul")
library(forecast)
library(randomForest)
library(data.table)
library(ggplot2)
library(ggfortify)
sales = fread("bakery_sales.csv")
View(sales)
str(sales)
# Fix Date
sales$Date = as.Date(sales$Date, format="%Y-%m-%d")
sales$Time = NULL
str(sales)
min(sales$Date)
max(sales$Date)
# Understand Products
unique(sales$Item)
sales$quantity = 1
sales[,.(quantity=sum(quantity)),by="Item"][order(-quantity)]
product = sales[Item == "Bread", .(quantity = sum(quantity)), by = "Date"]
product[,mean(quantity),by=weekdays(Date)]
# create complete times series
dateseq = data.table(Date=seq(min(sales$Date),max(sales$Date), by="days"))
product = merge(dateseq, product, by="Date", all.x=TRUE)
library(forecast)
library(randomForest)
library(data.table)
library(ggplot2)
library(ggfortify)
sales = fread("bakery_sales.csv")
View(sales)
str(sales)
# Fix Date
sales$Date = as.Date(sales$Date, format="%Y-%m-%d")
sales$Time = NULL
str(sales)
min(sales$Date)
max(sales$Date)
# Understand Products
unique(sales$Item)
sales$quantity = 1
sales[,.(quantity=sum(quantity)),by="Item"][order(-quantity)]
library(forecast)
library(randomForest)
library(data.table)
library(ggplot2)
library(ggfortify)
sales = fread("bakery_sales.csv")
View(sales)
str(sales)
# Fix Date
sales$Date = as.Date(sales$Date, format="%Y-%m-%d")
sales$Time = NULL
str(sales)
min(sales$Date)
max(sales$Date)
# Understand Products
unique(sales$Item)
sales$quantity = 1
sales[,.(quantity=sum(quantity)),by="Item"][order(-quantity)]
product = sales[Item == "Bread", .(quantity = sum(quantity)), by = "Date"]
product[,mean(quantity),by=weekdays(Date)]
# create complete times series
dateseq = data.table(Date=seq(min(sales$Date),max(sales$Date), by="days"))
product = merge(dateseq, product, by="Date", all.x=TRUE)
View(product)
product$is_closed = ifelse(is.na(product$quantity),1,0)
product[is.na(quantity),"quantity"]=0
# create some additional features
product$day_of_week = weekdays(product$Date)
product$week_of_year = week(product$Date)
product = product[-c(1:6, 161:162),]
View(product)
# create actual times series
product_ts = ts(product$quantity, frequency = 7)
# plot with base R
plot(product_ts)
# plot with forecast package
autoplot(product_ts, color="green4", alpha = 0.5, size = 2) +
ggtitle("Bread Sales over Time") +
labs(y="Sold Units", x="Weeks")
# decompose time series
decomposed_ts = decompose(product_ts)
autoplot(decomposed_ts)
index = tail(1:nrow(product),28)
train_product = product[-index,]
test_product = product[index,]
train_product_ts = ts(train_product$quantity, frequency = 7)
forecast = naive(train_product_ts, h = 7)
tail(train_product$quantity,1)
View(forecast$mean)
autoplot(forecast, PI = FALSE)
# RMSE calculation
RMSE=function(actual, predicted){
rmse = sqrt(mean((actual-predicted)^2))
return(rmse)
}
str(test_product)
#create test dataframe
new_train = train[,9]
new_train <- as.numeric(new_train)
new_train <- as.data.frame(new_train)
str(new_train)
#add features
new_train$date = calendar$date[1:1913]
new_train$day = calendar$weekday[1:1913]
new_train$week = week(new_train$date)
#eliminate first 6 entries and last 4 entries to have full weeks only
new_train = new_train[-c(1:6, 1910:1913),]
#rename column
names(new_train)[1] <- "quantity"
View(new_train)
#create time series data
product_ts = ts(new_train$quantity, frequency = 7)
plot(product_ts)
### Create Test and Training Data
######################################################
index = tail(1:nrow(new_train),28)
train_product = new_train[-index,]
test_product = new_train[index,]
# walkforward validation
walkforward_evaluation = function(train_product, test_product){
history = train_product
performance_collector = c()
for (w in unique(test_product$week_of_year)){
#create time series of history
history_ts = ts(history$quantity, frequency = 7)
#make forecast and assess RMSE
predicted = naive(history_ts, h = 7)$mean
actual = test_product[week_of_year == w,,]$quantity
performance = RMSE(actual, predicted)
# update history and collect performance
history = rbind(history, test_product[week_of_year == w,,])
performance_collector = c(performance_collector, performance)
}
return(performance_collector)
}
naive_error = walkforward_evaluation(train_product, test_product)
mean(naive_error)
for (w in unique(test_product$week)){
actual = test_product[week == w,,]$quantity
print(actual)
}
actual = test_product[14,,]$quantity
print(actual)
for (w in unique(test_product$week)){
test_product[week == w,,]$quantity
}
w=0
for (w in unique(test_product$week)){
test_product[week == w,,]$quantity
}
print(str(w))
